{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\n!pip uninstall -y numpy scipy scikit-learn torch torchvision torchaudio tensorboard tensorflow keras matplotlib\n\n!pip install numpy==1.21.6\n\n!pip install torch==1.13.1 torchvision==0.14.1 torchaudio==0.13.1\n!pip install transformers==4.25.1 accelerate bitsandbytes\n!pip install datasets==2.21.0 huggingface-hub==0.34.0 \n!pip install groq spacy nltk tiktoken\n\n!python -m spacy download en_core_web_sm\n!git clone https://github.com/ilatims-b/LLMLingua.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T17:24:49.196063Z","iopub.execute_input":"2025-08-24T17:24:49.196301Z","iopub.status.idle":"2025-08-24T17:29:02.724175Z","shell.execute_reply.started":"2025-08-24T17:24:49.196279Z","shell.execute_reply":"2025-08-24T17:29:02.723263Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: numpy 1.26.4\nUninstalling numpy-1.26.4:\n  Successfully uninstalled numpy-1.26.4\nFound existing installation: scipy 1.15.3\nUninstalling scipy-1.15.3:\n  Successfully uninstalled scipy-1.15.3\nFound existing installation: scikit-learn 1.2.2\nUninstalling scikit-learn-1.2.2:\n  Successfully uninstalled scikit-learn-1.2.2\nFound existing installation: torch 2.6.0+cu124\nUninstalling torch-2.6.0+cu124:\n  Successfully uninstalled torch-2.6.0+cu124\nFound existing installation: torchvision 0.21.0+cu124\nUninstalling torchvision-0.21.0+cu124:\n  Successfully uninstalled torchvision-0.21.0+cu124\nFound existing installation: torchaudio 2.6.0+cu124\nUninstalling torchaudio-2.6.0+cu124:\n  Successfully uninstalled torchaudio-2.6.0+cu124\nFound existing installation: tensorboard 2.18.0\nUninstalling tensorboard-2.18.0:\n  Successfully uninstalled tensorboard-2.18.0\nFound existing installation: tensorflow 2.18.0\nUninstalling tensorflow-2.18.0:\n  Successfully uninstalled tensorflow-2.18.0\nFound existing installation: keras 3.8.0\nUninstalling keras-3.8.0:\n  Successfully uninstalled keras-3.8.0\nFound existing installation: matplotlib 3.7.2\nUninstalling matplotlib-3.7.2:\n  Successfully uninstalled matplotlib-3.7.2\n\u001b[31mERROR: Ignored the following versions that require a different python version: 1.21.2 Requires-Python >=3.7,<3.11; 1.21.3 Requires-Python >=3.7,<3.11; 1.21.4 Requires-Python >=3.7,<3.11; 1.21.5 Requires-Python >=3.7,<3.11; 1.21.6 Requires-Python >=3.7,<3.11\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement numpy==1.21.6 (from versions: 1.3.0, 1.4.1, 1.5.0, 1.5.1, 1.6.0, 1.6.1, 1.6.2, 1.7.0, 1.7.1, 1.7.2, 1.8.0, 1.8.1, 1.8.2, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.10.0.post2, 1.10.1, 1.10.2, 1.10.4, 1.11.0, 1.11.1, 1.11.2, 1.11.3, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 1.13.3, 1.14.0, 1.14.1, 1.14.2, 1.14.3, 1.14.4, 1.14.5, 1.14.6, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.15.4, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.16.4, 1.16.5, 1.16.6, 1.17.0, 1.17.1, 1.17.2, 1.17.3, 1.17.4, 1.17.5, 1.18.0, 1.18.1, 1.18.2, 1.18.3, 1.18.4, 1.18.5, 1.19.0, 1.19.1, 1.19.2, 1.19.3, 1.19.4, 1.19.5, 1.20.0, 1.20.1, 1.20.2, 1.20.3, 1.21.0, 1.21.1, 1.22.0, 1.22.1, 1.22.2, 1.22.3, 1.22.4, 1.23.0, 1.23.1, 1.23.2, 1.23.3, 1.23.4, 1.23.5, 1.24.0, 1.24.1, 1.24.2, 1.24.3, 1.24.4, 1.25.0, 1.25.1, 1.25.2, 1.26.0, 1.26.1, 1.26.2, 1.26.3, 1.26.4, 2.0.0, 2.0.1, 2.0.2, 2.1.0, 2.1.1, 2.1.2, 2.1.3, 2.2.0, 2.2.1, 2.2.2, 2.2.3, 2.2.4, 2.2.5, 2.2.6, 2.3.0, 2.3.1, 2.3.2)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for numpy==1.21.6\u001b[0m\u001b[31m\n\u001b[0mCollecting torch==1.13.1\n  Downloading torch-1.13.1-cp311-cp311-manylinux1_x86_64.whl.metadata (24 kB)\n\u001b[31mERROR: Ignored the following yanked versions: 0.1.6, 0.1.7, 0.1.8, 0.1.9, 0.2.0, 0.2.1, 0.2.2, 0.2.2.post2, 0.2.2.post3, 0.15.0\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torchvision==0.14.1 (from versions: 0.15.1, 0.15.2, 0.16.0, 0.16.1, 0.16.2, 0.17.0, 0.17.1, 0.17.2, 0.18.0, 0.18.1, 0.19.0, 0.19.1, 0.20.0, 0.20.1, 0.21.0, 0.22.0, 0.22.1, 0.23.0)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for torchvision==0.14.1\u001b[0m\u001b[31m\n\u001b[0mCollecting transformers==4.25.1\n  Downloading transformers-4.25.1-py3-none-any.whl.metadata (93 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (0.33.1)\nCollecting numpy>=1.17 (from transformers==4.25.1)\n  Downloading numpy-2.3.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (2.32.4)\nCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.25.1)\n  Downloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (4.67.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\nCollecting torch>=2.0.0 (from accelerate)\n  Downloading torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.25.1) (2025.5.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.25.1) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.25.1) (1.1.5)\nCollecting sympy>=1.13.3 (from torch>=2.0.0->accelerate)\n  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-cublas-cu12==12.8.4.1 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-cusparse-cu12==12.5.8.93 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-cusparselt-cu12==0.7.1 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\nCollecting nvidia-nccl-cu12==2.27.3 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\nCollecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvjitlink-cu12==12.8.93 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\nCollecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\nCollecting triton==3.4.0 (from torch>=2.0.0->accelerate)\n  Downloading triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\nRequirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.4.0->torch>=2.0.0->accelerate) (75.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.25.1) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.25.1) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.25.1) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.25.1) (2025.6.15)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\nDownloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading bitsandbytes-0.47.0-py3-none-manylinux_2_24_x86_64.whl (61.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading numpy-2.3.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m107.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl (888.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m888.1/888.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.4/322.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.5/155.5 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tokenizers, nvidia-cusparselt-cu12, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, transformers, nvidia-cusolver-cu12, torch, bitsandbytes\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.2\n    Uninstalling tokenizers-0.21.2:\n      Successfully uninstalled tokenizers-0.21.2\n  Attempting uninstall: nvidia-cusparselt-cu12\n    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n  Attempting uninstall: triton\n    Found existing installation: triton 3.2.0\n    Uninstalling triton-3.2.0:\n      Successfully uninstalled triton-3.2.0\n  Attempting uninstall: sympy\n    Found existing installation: sympy 1.13.1\n    Uninstalling sympy-1.13.1:\n      Successfully uninstalled sympy-1.13.1\n  Attempting uninstall: nvidia-nvtx-cu12\n    Found existing installation: nvidia-nvtx-cu12 12.4.127\n    Uninstalling nvidia-nvtx-cu12-12.4.127:\n      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-nccl-cu12\n    Found existing installation: nvidia-nccl-cu12 2.21.5\n    Uninstalling nvidia-nccl-cu12-2.21.5:\n      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.52.4\n    Uninstalling transformers-4.52.4:\n      Successfully uninstalled transformers-4.52.4\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngensim 4.3.3 requires scipy<1.14.0,>=1.7.0, which is not installed.\nlibpysal 4.9.2 requires scipy>=1.8, which is not installed.\ntreelite 4.4.1 requires scipy, which is not installed.\ncuml-cu12 25.2.1 requires scipy>=1.8.0, which is not installed.\nwoodwork 0.31.0 requires scikit-learn>=1.1.0, which is not installed.\nwoodwork 0.31.0 requires scipy>=1.10.0, which is not installed.\nydata-profiling 4.16.1 requires matplotlib<=3.10,>=3.5, which is not installed.\nydata-profiling 4.16.1 requires scipy<1.16,>=1.4.1, which is not installed.\nboruta 0.4.3 requires scikit-learn>=0.17.1, which is not installed.\nboruta 0.4.3 requires scipy>=0.17.0, which is not installed.\nbayesian-optimization 3.0.0 requires scikit-learn<2.0.0,>=1.0.0, which is not installed.\nbayesian-optimization 3.0.0 requires scipy<2.0.0,>=1.0.0; python_version < \"3.13\", which is not installed.\nscikit-surprise 1.1.4 requires scipy>=1.6.0, which is not installed.\nfeaturetools 1.31.0 requires scipy>=1.10.0, which is not installed.\nplotly-express 0.4.1 requires scipy>=0.18, which is not installed.\neasyocr 1.7.2 requires scipy, which is not installed.\neasyocr 1.7.2 requires torchvision>=0.5, which is not installed.\nimagehash 4.3.1 requires scipy, which is not installed.\nxgboost 2.0.3 requires scipy, which is not installed.\ncatboost 1.2.8 requires matplotlib, which is not installed.\ncatboost 1.2.8 requires scipy, which is not installed.\nfury 0.12.0 requires scipy>=1.0, which is not installed.\ntpot 0.12.1 requires scikit-learn>=0.22.0, which is not installed.\ntpot 0.12.1 requires scipy>=1.3.1, which is not installed.\nshap 0.44.1 requires scikit-learn, which is not installed.\nshap 0.44.1 requires scipy, which is not installed.\ncartopy 0.24.1 requires matplotlib>=3.6, which is not installed.\npyupset 0.1.1.post7 requires matplotlib, which is not installed.\nkaggle-environments 1.17.6 requires scipy>=1.11.2, which is not installed.\npymc3 3.11.4 requires scipy>=1.2.0, which is not installed.\ndipy 1.11.0 requires scipy>=1.8, which is not installed.\nopen-spiel 1.6 requires scipy>=1.10.1, which is not installed.\npyldavis 3.4.1 requires scikit-learn>=1.0.0, which is not installed.\npyldavis 3.4.1 requires scipy, which is not installed.\nphik 0.12.4 requires matplotlib>=2.2.3, which is not installed.\nphik 0.12.4 requires scipy>=1.5.2, which is not installed.\ntheano 1.0.5 requires scipy>=0.14, which is not installed.\nnilearn 0.10.4 requires scikit-learn>=1.0.0, which is not installed.\nnilearn 0.10.4 requires scipy>=1.8.0, which is not installed.\neli5 0.13.0 requires scikit-learn>=0.20, which is not installed.\neli5 0.13.0 requires scipy, which is not installed.\nipympl 0.9.7 requires matplotlib<4,>=3.5.0, which is not installed.\nstable-baselines3 2.1.0 requires matplotlib, which is not installed.\nscikit-learn-intelex 2025.6.1 requires scikit-learn>=0.22, which is not installed.\nseaborn 0.12.2 requires matplotlib!=3.6.1,>=3.1, which is not installed.\ncategory-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, which is not installed.\ncategory-encoders 2.7.0 requires scipy>=1.0.0, which is not installed.\nlime 0.2.0.1 requires matplotlib, which is not installed.\nlime 0.2.0.1 requires scikit-learn>=0.18, which is not installed.\nlime 0.2.0.1 requires scipy, which is not installed.\ncesium 0.12.4 requires scikit-learn>=0.22.1, which is not installed.\ncesium 0.12.4 requires scipy>=0.16.0, which is not installed.\ntheano-pymc 1.1.2 requires scipy>=0.14, which is not installed.\nhep-ml 0.8.0 requires scikit-learn>=1.0, which is not installed.\nhep-ml 0.8.0 requires scipy>=1.0.0, which is not installed.\nscikit-optimize 0.10.2 requires scikit-learn>=1.0.0, which is not installed.\nscikit-optimize 0.10.2 requires scipy>=1.1.0, which is not installed.\nmne 1.9.0 requires matplotlib>=3.6, which is not installed.\nmne 1.9.0 requires scipy>=1.9, which is not installed.\njax 0.5.2 requires scipy>=1.11.1, which is not installed.\ntsfresh 0.21.0 requires scikit-learn>=0.22.0, which is not installed.\ntsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", which is not installed.\nprophet 1.1.7 requires matplotlib>=2.0.0, which is not installed.\ngeemap 0.35.3 requires matplotlib, which is not installed.\ndopamine-rl 4.1.2 requires tensorflow>=2.2.0, which is not installed.\nsklearn-pandas 2.2.0 requires scikit-learn>=0.23.0, which is not installed.\nsklearn-pandas 2.2.0 requires scipy>=1.5.1, which is not installed.\nmatplotlib-venn 1.1.2 requires matplotlib, which is not installed.\nmatplotlib-venn 1.1.2 requires scipy, which is not installed.\ndatascience 0.17.6 requires matplotlib>=3.0.0, which is not installed.\ndatascience 0.17.6 requires scipy, which is not installed.\nlibrosa 0.11.0 requires scikit-learn>=1.1.0, which is not installed.\nlibrosa 0.11.0 requires scipy>=1.6.0, which is not installed.\nsentence-transformers 4.1.0 requires scikit-learn, which is not installed.\nsentence-transformers 4.1.0 requires scipy, which is not installed.\nmusic21 9.3.0 requires matplotlib, which is not installed.\nscikit-image 0.25.2 requires scipy>=1.11.4, which is not installed.\nmissingno 0.5.2 requires matplotlib, which is not installed.\nmissingno 0.5.2 requires scipy, which is not installed.\narviz 0.21.0 requires matplotlib>=3.5, which is not installed.\narviz 0.21.0 requires scipy>=1.9.0, which is not installed.\numap-learn 0.5.7 requires scikit-learn>=0.22, which is not installed.\numap-learn 0.5.7 requires scipy>=1.3.1, which is not installed.\ntimm 1.0.15 requires torchvision, which is not installed.\nhyperopt 0.2.7 requires scipy, which is not installed.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, which is not installed.\nimbalanced-learn 0.13.0 requires scipy<2,>=1.10.1, which is not installed.\nalbumentations 2.0.8 requires scipy>=1.10.0, which is not installed.\npymc 5.23.0 requires scipy>=1.4.1, which is not installed.\ntensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, which is not installed.\nclarabel 0.11.1 requires scipy, which is not installed.\nscs 3.2.7.post2 requires scipy, which is not installed.\nxarray-einstats 0.9.1 requires scipy>=1.11, which is not installed.\nfastai 2.7.19 requires matplotlib, which is not installed.\nfastai 2.7.19 requires scikit-learn, which is not installed.\nfastai 2.7.19 requires scipy, which is not installed.\nfastai 2.7.19 requires torchvision>=0.11, which is not installed.\nmizani 0.13.5 requires scipy>=1.8.0, which is not installed.\ncvxpy 1.6.6 requires scipy>=1.11.0, which is not installed.\nlightgbm 4.5.0 requires scipy, which is not installed.\nstatsmodels 0.14.4 requires scipy!=1.9.2,>=1.8, which is not installed.\nplotnine 0.14.5 requires matplotlib>=3.8.0, which is not installed.\nplotnine 0.14.5 requires scipy>=1.8.0, which is not installed.\nwordcloud 1.9.4 requires matplotlib, which is not installed.\npynndescent 0.5.13 requires scikit-learn>=0.18, which is not installed.\npynndescent 0.5.13 requires scipy>=1.0, which is not installed.\npytensor 2.31.4 requires scipy<2,>=1, which is not installed.\nhdbscan 0.8.40 requires scikit-learn>=0.20, which is not installed.\nhdbscan 0.8.40 requires scipy>=1.0, which is not installed.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\nbigframes 2.8.0 requires matplotlib>=3.7.1, which is not installed.\njaxlib 0.5.1 requires scipy>=1.11.1, which is not installed.\nstumpy 1.13.0 requires scipy>=1.10, which is not installed.\nyellowbrick 1.5 requires matplotlib!=3.0.0,>=2.0.2, which is not installed.\nyellowbrick 1.5 requires scikit-learn>=1.0.0, which is not installed.\nyellowbrick 1.5 requires scipy>=1.0.0, which is not installed.\nmlxtend 0.23.4 requires matplotlib>=3.0.0, which is not installed.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, which is not installed.\nmlxtend 0.23.4 requires scipy>=1.2.1, which is not installed.\nosqp 1.0.4 requires scipy>=0.13.2, which is not installed.\ngensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.3.2 which is incompatible.\nmkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.2 which is incompatible.\nmkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.2 which is incompatible.\nmkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.2 which is incompatible.\ncupy-cuda12x 13.4.1 requires numpy<2.3,>=1.22, but you have numpy 2.3.2 which is incompatible.\nnumba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.2 which is incompatible.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\nydata-profiling 4.16.1 requires numpy<2.2,>=1.16.0, but you have numpy 2.3.2 which is incompatible.\nonnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\nkaggle-environments 1.17.6 requires transformers>=4.33.1, but you have transformers 4.25.1 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.4 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.1 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\npandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nsentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.25.1 which is incompatible.\nfastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.8.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.47.0 numpy-2.3.2 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.3 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvtx-cu12-12.8.90 sympy-1.14.0 tokenizers-0.13.3 torch-2.8.0 transformers-4.25.1 triton-3.4.0\nCollecting datasets==2.21.0\n  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\nCollecting huggingface-hub==0.34.0\n  Downloading huggingface_hub-0.34.0-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets==2.21.0) (3.18.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets==2.21.0) (2.3.2)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.21.0) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets==2.21.0) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets==2.21.0) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets==2.21.0) (2.32.4)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets==2.21.0) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets==2.21.0) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets==2.21.0) (0.70.16)\nCollecting fsspec<=2024.6.1,>=2023.1.0 (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets==2.21.0)\n  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets==2.21.0) (3.12.13)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets==2.21.0) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets==2.21.0) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.34.0) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub==0.34.0) (1.1.5)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.21.0) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.21.0) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.21.0) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.21.0) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.21.0) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.21.0) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets==2.21.0) (1.20.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==2.21.0) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==2.21.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==2.21.0) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets==2.21.0) (2025.6.15)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.21.0) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.21.0) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets==2.21.0) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.21.0) (1.17.0)\nDownloading datasets-2.21.0-py3-none-any.whl (527 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading huggingface_hub-0.34.0-py3-none-any.whl (558 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m558.7/558.7 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: fsspec, huggingface-hub, datasets\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.5.1\n    Uninstalling fsspec-2025.5.1:\n      Successfully uninstalled fsspec-2025.5.1\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.33.1\n    Uninstalling huggingface-hub-0.33.1:\n      Successfully uninstalled huggingface-hub-0.33.1\n  Attempting uninstall: datasets\n    Found existing installation: datasets 3.6.0\n    Uninstalling datasets-3.6.0:\n      Successfully uninstalled datasets-3.6.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncuml-cu12 25.2.1 requires scipy>=1.8.0, which is not installed.\neasyocr 1.7.2 requires scipy, which is not installed.\neasyocr 1.7.2 requires torchvision>=0.5, which is not installed.\nkaggle-environments 1.17.6 requires scipy>=1.11.2, which is not installed.\nstable-baselines3 2.1.0 requires matplotlib, which is not installed.\ncesium 0.12.4 requires scikit-learn>=0.22.1, which is not installed.\ncesium 0.12.4 requires scipy>=0.16.0, which is not installed.\nsentence-transformers 4.1.0 requires scikit-learn, which is not installed.\nsentence-transformers 4.1.0 requires scipy, which is not installed.\ntimm 1.0.15 requires torchvision, which is not installed.\nfastai 2.7.19 requires matplotlib, which is not installed.\nfastai 2.7.19 requires scikit-learn, which is not installed.\nfastai 2.7.19 requires scipy, which is not installed.\nfastai 2.7.19 requires torchvision>=0.11, which is not installed.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\nbigframes 2.8.0 requires matplotlib>=3.7.1, which is not installed.\nkaggle-environments 1.17.6 requires transformers>=4.33.1, but you have transformers 4.25.1 which is incompatible.\nsentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.25.1 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.6.1 which is incompatible.\nfastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.8.0 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed datasets-2.21.0 fsspec-2024.6.1 huggingface-hub-0.34.0\nCollecting groq\n  Downloading groq-0.31.0-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.7)\nRequirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\nRequirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (4.9.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.11.7)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\nRequirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.14.0)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.13)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.10)\nRequirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.6)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.16.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.3.2)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.4)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (25.0)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\nRequirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\nRequirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\nRequirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.6.15)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\nRequirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (14.0.0)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.1)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\nDownloading groq-0.31.0-py3-none-any.whl (131 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.4/131.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: groq\nSuccessfully installed groq-0.31.0\nCollecting en-core-web-sm==3.8.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\n\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\nIf you are in a Jupyter or Colab notebook, you may need to restart Python in\norder to load all the package's dependencies. You can do this by selecting the\n'Restart kernel' or 'Restart runtime' option.\nCloning into 'LLMLingua'...\nremote: Enumerating objects: 581, done.\u001b[K\nremote: Counting objects: 100% (282/282), done.\u001b[K\nremote: Compressing objects: 100% (119/119), done.\u001b[K\nremote: Total 581 (delta 220), reused 153 (delta 153), pack-reused 299 (from 3)\u001b[K\nReceiving objects: 100% (581/581), 4.07 MiB | 20.25 MiB/s, done.\nResolving deltas: 100% (311/311), done.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"#not needed if not using groq\n!pip install groq","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T17:29:02.728063Z","iopub.execute_input":"2025-08-24T17:29:02.728308Z","iopub.status.idle":"2025-08-24T17:29:05.765899Z","shell.execute_reply.started":"2025-08-24T17:29:02.728283Z","shell.execute_reply":"2025-08-24T17:29:05.765163Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: groq in /usr/local/lib/python3.11/dist-packages (0.31.0)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq) (4.9.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq) (0.28.1)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq) (2.11.7)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq) (1.3.1)\nRequirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq) (4.14.0)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq) (3.10)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (2025.6.15)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.1)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from datasets import load_dataset\nimport json\nimport os","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T17:29:05.766998Z","iopub.execute_input":"2025-08-24T17:29:05.767781Z","iopub.status.idle":"2025-08-24T17:29:07.431819Z","shell.execute_reply.started":"2025-08-24T17:29:05.767755Z","shell.execute_reply":"2025-08-24T17:29:07.431037Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"data = []\nNUM_SAMPLES = 1\ndatasets = ['multifieldqa_en', 'triviaqa']\ncurrent_idx = 0  # Running index across datasets\n\nfor dataset_ in datasets:\n    data_ = load_dataset('THUDM/LongBench', dataset_, split='test', trust_remote_code=True)\n    \n    for idx, instance in enumerate(data_):\n        if idx >= NUM_SAMPLES:\n            break\n        \n        temp = {}\n        temp[\"dataset\"] = dataset_\n        temp[\"idx\"] = current_idx  # Use running index here instead of idx\n        temp[\"prompt\"] = instance['context'] + '\\n' + instance['input']\n        temp[\"answer\"] = instance['answers']\n        temp[\"length\"] = instance['length']\n        data.append(temp)\n        \n        current_idx += 1  # Increment the running index\n        \nos.makedirs(\"/kaggle/working/dataset\", exist_ok=True)\nwith open(\"/kaggle/working/dataset/longbench_1.json\", \"w\") as f:\n    json.dump(data, f, indent=4)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T17:29:07.432728Z","iopub.execute_input":"2025-08-24T17:29:07.433230Z","iopub.status.idle":"2025-08-24T17:29:13.020053Z","shell.execute_reply.started":"2025-08-24T17:29:07.433190Z","shell.execute_reply":"2025-08-24T17:29:13.019257Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/3.98k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c3e2a6cfe0d438a968efbc215050f75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/16.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e23567d64dcd4089a8214eb4d7659513"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/114M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96582a1328c842c8a0857205f4d4fb58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b462a1f4093b48548a8f71655f863693"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98f3023dda9d456e88939b07038e76b5"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"\nos.chdir('/kaggle/working/LLMLingua/experiments/llmlingua2/data_collection')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T17:29:13.022083Z","iopub.execute_input":"2025-08-24T17:29:13.022839Z","iopub.status.idle":"2025-08-24T17:29:13.026624Z","shell.execute_reply.started":"2025-08-24T17:29:13.022811Z","shell.execute_reply":"2025-08-24T17:29:13.025883Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"!pip install openai==0.28#not needed if not using gpt4","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n#generating compressed prompts from gpt4 for data annotation\n!python compress.py --load_origin_from /kaggle/working/dataset/longbench_1.json \\\n--chunk_size 512 \\\n--compressor groq\\\n--model_name openai/gpt-oss-20b \\\n--api_key \"your api key :)\"\\\n--save_path /kaggle/working/dataset/longbench_1_compressed.json","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T17:29:13.027474Z","iopub.execute_input":"2025-08-24T17:29:13.027718Z","iopub.status.idle":"2025-08-24T17:36:25.543001Z","shell.execute_reply.started":"2025-08-24T17:29:13.027690Z","shell.execute_reply":"2025-08-24T17:36:25.542253Z"}},"outputs":[{"name":"stdout","text":"num data: 2\nYou are an excellent linguist and very good at compressing passages into short expressions by removing unimportant words, while retaining as much information as possible.\nCompress some text to short expressions, and such that you (GPT-4) can reconstruct it as close as possible to the original. Unlike the usual text compression, I need you to comply with the 5 conditions below: 1. You can ONLY remove unimportant words. 2. Do not change the order of words. 3. Do not change the original words, e.g. 'asking'->'ask' is NOT OK, 'current'->'now' is NOT OK. 4. Do not use abbreviations or emojis, e.g. 'without'->'w/o' is NOT OK, 'as soon as possible'->'ASAP' is NOT OK. 5. Do not add new words or symbols, this is very important. For example, 'dedicate 3 hours to each chapter'->'3 hours/chapter' is NOT OK because you add new token '/', just compress it into '3 hours each chapter'. '30 eggs plus 20 eggs equals 50 eggs'->'30+20=50' is also NOT OK becuase you add new symbols + and =, just compress it into '30 plus 20 equals 50'. \nCompress the origin aggressively by removing words only. Compress the origin as short as you can, while retaining as much information as possible. \nIf you understand, please compress the following text: \n{text_to_compress}\nThe compressed text is: \n  0%|                                                     | 0/2 [00:00<?, ?it/s]num chunk: 3\n 50%|██████████████████████▌                      | 1/2 [00:24<00:24, 24.06s/it]num chunk: 12\n100%|████████████████████████████████████████████| 2/2 [07:10<00:00, 215.18s/it]\n/kaggle/working/dataset/longbench_1_compressed.json 430.3526976108551\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"os.makedirs(\"/kaggle/working/dataset/longbench_hf_dataset\", exist_ok=True)\njson.dump(list(json.load(open(\"/kaggle/working/dataset/longbench_1_compressed.json\")).values()), open(\"/kaggle/working/dataset/longbench_hf_dataset/train.json\", \"w\"), ensure_ascii=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T17:36:35.928589Z","iopub.execute_input":"2025-08-24T17:36:35.929244Z","iopub.status.idle":"2025-08-24T17:36:35.936236Z","shell.execute_reply.started":"2025-08-24T17:36:35.929213Z","shell.execute_reply":"2025-08-24T17:36:35.935615Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"#train data annotations\n!python label_word.py \\\n--load_prompt_from /kaggle/working/dataset/longbench_hf_dataset  \\\n--window_size 400 \\\n--save_path /kaggle/working/dataset/longbench_1_labelled.json","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T17:36:40.297864Z","iopub.execute_input":"2025-08-24T17:36:40.298449Z","iopub.status.idle":"2025-08-24T17:36:47.113374Z","shell.execute_reply.started":"2025-08-24T17:36:40.298425Z","shell.execute_reply":"2025-08-24T17:36:47.112384Z"}},"outputs":[{"name":"stdout","text":"Generating train split: 2 examples [00:00, 57.04 examples/s]\n15it [00:01, 13.07it/s]\nwindow size: 400, comp rate: 0.14955640453642954, hitting_rate: 0.1469762469261397, retrieval rate: 0.14175059371948887\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"#train data filtering, they have defined various metrics in paper\n!python filter.py \\\n--load_path /kaggle/working/dataset/longbench_1_labelled.pt\\\n--save_path /kaggle/working/dataset/longbench_1_filtered.pt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T17:36:51.938195Z","iopub.execute_input":"2025-08-24T17:36:51.939026Z","iopub.status.idle":"2025-08-24T17:36:54.011284Z","shell.execute_reply.started":"2025-08-24T17:36:51.938996Z","shell.execute_reply":"2025-08-24T17:36:54.010512Z"}},"outputs":[{"name":"stdout","text":"15\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"\nos.chdir('/kaggle/working/LLMLingua/experiments/llmlingua2/model_training')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T17:36:56.778305Z","iopub.execute_input":"2025-08-24T17:36:56.778614Z","iopub.status.idle":"2025-08-24T17:36:56.782859Z","shell.execute_reply.started":"2025-08-24T17:36:56.778589Z","shell.execute_reply":"2025-08-24T17:36:56.782083Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"!pip install --force-reinstall tensorboard==2.13.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T17:37:00.237946Z","iopub.execute_input":"2025-08-24T17:37:00.238242Z","iopub.status.idle":"2025-08-24T17:37:20.634740Z","shell.execute_reply.started":"2025-08-24T17:37:00.238218Z","shell.execute_reply":"2025-08-24T17:37:20.634005Z"}},"outputs":[{"name":"stdout","text":"Collecting tensorboard==2.13.0\n  Downloading tensorboard-2.13.0-py3-none-any.whl.metadata (1.8 kB)\nCollecting absl-py>=0.4 (from tensorboard==2.13.0)\n  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\nCollecting grpcio>=1.48.2 (from tensorboard==2.13.0)\n  Downloading grpcio-1.74.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\nCollecting google-auth<3,>=1.6.3 (from tensorboard==2.13.0)\n  Downloading google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\nCollecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard==2.13.0)\n  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\nCollecting markdown>=2.6.8 (from tensorboard==2.13.0)\n  Downloading markdown-3.8.2-py3-none-any.whl.metadata (5.1 kB)\nCollecting numpy>=1.12.0 (from tensorboard==2.13.0)\n  Using cached numpy-2.3.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\nCollecting protobuf>=3.19.6 (from tensorboard==2.13.0)\n  Downloading protobuf-6.32.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\nCollecting requests<3,>=2.21.0 (from tensorboard==2.13.0)\n  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\nCollecting setuptools>=41.0.0 (from tensorboard==2.13.0)\n  Downloading setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)\nCollecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard==2.13.0)\n  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\nCollecting werkzeug>=1.0.1 (from tensorboard==2.13.0)\n  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\nCollecting wheel>=0.26 (from tensorboard==2.13.0)\n  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\nCollecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard==2.13.0)\n  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\nCollecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard==2.13.0)\n  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\nCollecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard==2.13.0)\n  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\nCollecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard==2.13.0)\n  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\nCollecting charset_normalizer<4,>=2 (from requests<3,>=2.21.0->tensorboard==2.13.0)\n  Downloading charset_normalizer-3.4.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (36 kB)\nCollecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorboard==2.13.0)\n  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\nCollecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorboard==2.13.0)\n  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\nCollecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard==2.13.0)\n  Downloading certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\nCollecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard==2.13.0)\n  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\nCollecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.13.0)\n  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\nCollecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard==2.13.0)\n  Downloading oauthlib-3.3.1-py3-none-any.whl.metadata (7.9 kB)\nDownloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.1/216.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\nDownloading grpcio-1.74.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m110.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading markdown-3.8.2-py3-none-any.whl (106 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hUsing cached numpy-2.3.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.9 MB)\nDownloading protobuf-6.32.0-cp39-abi3-manylinux2014_x86_64.whl (322 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.0/322.0 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading setuptools-80.9.0-py3-none-any.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading wheel-0.45.1-py3-none-any.whl (72 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading cachetools-5.5.2-py3-none-any.whl (10 kB)\nDownloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.2/161.2 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading charset_normalizer-3.4.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (150 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.3/150.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\nDownloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\nDownloading rsa-4.9.1-py3-none-any.whl (34 kB)\nDownloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.8/129.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading oauthlib-3.3.1-py3-none-any.whl (160 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.1/160.1 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.1/83.1 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: wheel, urllib3, tensorboard-data-server, setuptools, pyasn1, protobuf, oauthlib, numpy, MarkupSafe, markdown, idna, grpcio, charset_normalizer, certifi, cachetools, absl-py, werkzeug, rsa, requests, pyasn1-modules, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard\n  Attempting uninstall: wheel\n    Found existing installation: wheel 0.45.1\n    Uninstalling wheel-0.45.1:\n      Successfully uninstalled wheel-0.45.1\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 2.5.0\n    Uninstalling urllib3-2.5.0:\n      Successfully uninstalled urllib3-2.5.0\n  Attempting uninstall: tensorboard-data-server\n    Found existing installation: tensorboard-data-server 0.7.2\n    Uninstalling tensorboard-data-server-0.7.2:\n      Successfully uninstalled tensorboard-data-server-0.7.2\n  Attempting uninstall: setuptools\n    Found existing installation: setuptools 75.2.0\n    Uninstalling setuptools-75.2.0:\n      Successfully uninstalled setuptools-75.2.0\n  Attempting uninstall: pyasn1\n    Found existing installation: pyasn1 0.6.1\n    Uninstalling pyasn1-0.6.1:\n      Successfully uninstalled pyasn1-0.6.1\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n  Attempting uninstall: oauthlib\n    Found existing installation: oauthlib 3.3.1\n    Uninstalling oauthlib-3.3.1:\n      Successfully uninstalled oauthlib-3.3.1\n  Attempting uninstall: numpy\n    Found existing installation: numpy 2.3.2\n    Uninstalling numpy-2.3.2:\n      Successfully uninstalled numpy-2.3.2\n  Attempting uninstall: MarkupSafe\n    Found existing installation: MarkupSafe 3.0.2\n    Uninstalling MarkupSafe-3.0.2:\n      Successfully uninstalled MarkupSafe-3.0.2\n  Attempting uninstall: markdown\n    Found existing installation: Markdown 3.8.2\n    Uninstalling Markdown-3.8.2:\n      Successfully uninstalled Markdown-3.8.2\n  Attempting uninstall: idna\n    Found existing installation: idna 3.10\n    Uninstalling idna-3.10:\n      Successfully uninstalled idna-3.10\n  Attempting uninstall: grpcio\n    Found existing installation: grpcio 1.73.1\n    Uninstalling grpcio-1.73.1:\n      Successfully uninstalled grpcio-1.73.1\n  Attempting uninstall: charset_normalizer\n    Found existing installation: charset-normalizer 3.4.2\n    Uninstalling charset-normalizer-3.4.2:\n      Successfully uninstalled charset-normalizer-3.4.2\n  Attempting uninstall: certifi\n    Found existing installation: certifi 2025.6.15\n    Uninstalling certifi-2025.6.15:\n      Successfully uninstalled certifi-2025.6.15\n  Attempting uninstall: cachetools\n    Found existing installation: cachetools 5.5.2\n    Uninstalling cachetools-5.5.2:\n      Successfully uninstalled cachetools-5.5.2\n  Attempting uninstall: absl-py\n    Found existing installation: absl-py 1.4.0\n    Uninstalling absl-py-1.4.0:\n      Successfully uninstalled absl-py-1.4.0\n  Attempting uninstall: werkzeug\n    Found existing installation: Werkzeug 3.1.3\n    Uninstalling Werkzeug-3.1.3:\n      Successfully uninstalled Werkzeug-3.1.3\n  Attempting uninstall: rsa\n    Found existing installation: rsa 4.9.1\n    Uninstalling rsa-4.9.1:\n      Successfully uninstalled rsa-4.9.1\n  Attempting uninstall: requests\n    Found existing installation: requests 2.32.4\n    Uninstalling requests-2.32.4:\n      Successfully uninstalled requests-2.32.4\n  Attempting uninstall: pyasn1-modules\n    Found existing installation: pyasn1_modules 0.4.2\n    Uninstalling pyasn1_modules-0.4.2:\n      Successfully uninstalled pyasn1_modules-0.4.2\n  Attempting uninstall: requests-oauthlib\n    Found existing installation: requests-oauthlib 2.0.0\n    Uninstalling requests-oauthlib-2.0.0:\n      Successfully uninstalled requests-oauthlib-2.0.0\n  Attempting uninstall: google-auth\n    Found existing installation: google-auth 2.40.3\n    Uninstalling google-auth-2.40.3:\n      Successfully uninstalled google-auth-2.40.3\n  Attempting uninstall: google-auth-oauthlib\n    Found existing installation: google-auth-oauthlib 1.2.2\n    Uninstalling google-auth-oauthlib-1.2.2:\n      Successfully uninstalled google-auth-oauthlib-1.2.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngensim 4.3.3 requires scipy<1.14.0,>=1.7.0, which is not installed.\nlibpysal 4.9.2 requires scipy>=1.8, which is not installed.\ntreelite 4.4.1 requires scipy, which is not installed.\ncuml-cu12 25.2.1 requires scipy>=1.8.0, which is not installed.\nwoodwork 0.31.0 requires scikit-learn>=1.1.0, which is not installed.\nwoodwork 0.31.0 requires scipy>=1.10.0, which is not installed.\nydata-profiling 4.16.1 requires matplotlib<=3.10,>=3.5, which is not installed.\nydata-profiling 4.16.1 requires scipy<1.16,>=1.4.1, which is not installed.\nmpld3 0.5.10 requires matplotlib, which is not installed.\nboruta 0.4.3 requires scikit-learn>=0.17.1, which is not installed.\nboruta 0.4.3 requires scipy>=0.17.0, which is not installed.\nbayesian-optimization 3.0.0 requires scikit-learn<2.0.0,>=1.0.0, which is not installed.\nbayesian-optimization 3.0.0 requires scipy<2.0.0,>=1.0.0; python_version < \"3.13\", which is not installed.\nscikit-surprise 1.1.4 requires scipy>=1.6.0, which is not installed.\nfeaturetools 1.31.0 requires scipy>=1.10.0, which is not installed.\nplotly-express 0.4.1 requires scipy>=0.18, which is not installed.\neasyocr 1.7.2 requires scipy, which is not installed.\neasyocr 1.7.2 requires torchvision>=0.5, which is not installed.\nimagehash 4.3.1 requires scipy, which is not installed.\nxgboost 2.0.3 requires scipy, which is not installed.\ncatboost 1.2.8 requires matplotlib, which is not installed.\ncatboost 1.2.8 requires scipy, which is not installed.\nfury 0.12.0 requires scipy>=1.0, which is not installed.\ntpot 0.12.1 requires scikit-learn>=0.22.0, which is not installed.\ntpot 0.12.1 requires scipy>=1.3.1, which is not installed.\nshap 0.44.1 requires scikit-learn, which is not installed.\nshap 0.44.1 requires scipy, which is not installed.\ncartopy 0.24.1 requires matplotlib>=3.6, which is not installed.\npyupset 0.1.1.post7 requires matplotlib, which is not installed.\nkaggle-environments 1.17.6 requires scipy>=1.11.2, which is not installed.\npymc3 3.11.4 requires scipy>=1.2.0, which is not installed.\ndipy 1.11.0 requires scipy>=1.8, which is not installed.\nopen-spiel 1.6 requires scipy>=1.10.1, which is not installed.\npyldavis 3.4.1 requires scikit-learn>=1.0.0, which is not installed.\npyldavis 3.4.1 requires scipy, which is not installed.\nphik 0.12.4 requires matplotlib>=2.2.3, which is not installed.\nphik 0.12.4 requires scipy>=1.5.2, which is not installed.\nkeras-tuner 1.4.7 requires keras, which is not installed.\ntheano 1.0.5 requires scipy>=0.14, which is not installed.\nnilearn 0.10.4 requires scikit-learn>=1.0.0, which is not installed.\nnilearn 0.10.4 requires scipy>=1.8.0, which is not installed.\neli5 0.13.0 requires scikit-learn>=0.20, which is not installed.\neli5 0.13.0 requires scipy, which is not installed.\nipympl 0.9.7 requires matplotlib<4,>=3.5.0, which is not installed.\nstable-baselines3 2.1.0 requires matplotlib, which is not installed.\nscikit-learn-intelex 2025.6.1 requires scikit-learn>=0.22, which is not installed.\nseaborn 0.12.2 requires matplotlib!=3.6.1,>=3.1, which is not installed.\ncategory-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, which is not installed.\ncategory-encoders 2.7.0 requires scipy>=1.0.0, which is not installed.\nlime 0.2.0.1 requires matplotlib, which is not installed.\nlime 0.2.0.1 requires scikit-learn>=0.18, which is not installed.\nlime 0.2.0.1 requires scipy, which is not installed.\ncesium 0.12.4 requires scikit-learn>=0.22.1, which is not installed.\ncesium 0.12.4 requires scipy>=0.16.0, which is not installed.\ntheano-pymc 1.1.2 requires scipy>=0.14, which is not installed.\nhep-ml 0.8.0 requires scikit-learn>=1.0, which is not installed.\nhep-ml 0.8.0 requires scipy>=1.0.0, which is not installed.\nscikit-optimize 0.10.2 requires scikit-learn>=1.0.0, which is not installed.\nscikit-optimize 0.10.2 requires scipy>=1.1.0, which is not installed.\nmne 1.9.0 requires matplotlib>=3.6, which is not installed.\nmne 1.9.0 requires scipy>=1.9, which is not installed.\njax 0.5.2 requires scipy>=1.11.1, which is not installed.\ntsfresh 0.21.0 requires scikit-learn>=0.22.0, which is not installed.\ntsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", which is not installed.\nprophet 1.1.7 requires matplotlib>=2.0.0, which is not installed.\ngeemap 0.35.3 requires matplotlib, which is not installed.\ndopamine-rl 4.1.2 requires tensorflow>=2.2.0, which is not installed.\nsklearn-pandas 2.2.0 requires scikit-learn>=0.23.0, which is not installed.\nsklearn-pandas 2.2.0 requires scipy>=1.5.1, which is not installed.\nmatplotlib-venn 1.1.2 requires matplotlib, which is not installed.\nmatplotlib-venn 1.1.2 requires scipy, which is not installed.\ndatascience 0.17.6 requires matplotlib>=3.0.0, which is not installed.\ndatascience 0.17.6 requires scipy, which is not installed.\nlibrosa 0.11.0 requires scikit-learn>=1.1.0, which is not installed.\nlibrosa 0.11.0 requires scipy>=1.6.0, which is not installed.\nsentence-transformers 4.1.0 requires scikit-learn, which is not installed.\nsentence-transformers 4.1.0 requires scipy, which is not installed.\nmusic21 9.3.0 requires matplotlib, which is not installed.\nscikit-image 0.25.2 requires scipy>=1.11.4, which is not installed.\nmissingno 0.5.2 requires matplotlib, which is not installed.\nmissingno 0.5.2 requires scipy, which is not installed.\narviz 0.21.0 requires matplotlib>=3.5, which is not installed.\narviz 0.21.0 requires scipy>=1.9.0, which is not installed.\numap-learn 0.5.7 requires scikit-learn>=0.22, which is not installed.\numap-learn 0.5.7 requires scipy>=1.3.1, which is not installed.\ntimm 1.0.15 requires torchvision, which is not installed.\nhyperopt 0.2.7 requires scipy, which is not installed.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, which is not installed.\nimbalanced-learn 0.13.0 requires scipy<2,>=1.10.1, which is not installed.\nalbumentations 2.0.8 requires scipy>=1.10.0, which is not installed.\npymc 5.23.0 requires scipy>=1.4.1, which is not installed.\ntensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, which is not installed.\nclarabel 0.11.1 requires scipy, which is not installed.\nscs 3.2.7.post2 requires scipy, which is not installed.\nxarray-einstats 0.9.1 requires scipy>=1.11, which is not installed.\nfastai 2.7.19 requires matplotlib, which is not installed.\nfastai 2.7.19 requires scikit-learn, which is not installed.\nfastai 2.7.19 requires scipy, which is not installed.\nfastai 2.7.19 requires torchvision>=0.11, which is not installed.\nmizani 0.13.5 requires scipy>=1.8.0, which is not installed.\ncvxpy 1.6.6 requires scipy>=1.11.0, which is not installed.\nlightgbm 4.5.0 requires scipy, which is not installed.\nstatsmodels 0.14.4 requires scipy!=1.9.2,>=1.8, which is not installed.\nplotnine 0.14.5 requires matplotlib>=3.8.0, which is not installed.\nplotnine 0.14.5 requires scipy>=1.8.0, which is not installed.\nwordcloud 1.9.4 requires matplotlib, which is not installed.\npynndescent 0.5.13 requires scikit-learn>=0.18, which is not installed.\npynndescent 0.5.13 requires scipy>=1.0, which is not installed.\npytensor 2.31.4 requires scipy<2,>=1, which is not installed.\nhdbscan 0.8.40 requires scikit-learn>=0.20, which is not installed.\nhdbscan 0.8.40 requires scipy>=1.0, which is not installed.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\nbigframes 2.8.0 requires matplotlib>=3.7.1, which is not installed.\njaxlib 0.5.1 requires scipy>=1.11.1, which is not installed.\nstumpy 1.13.0 requires scipy>=1.10, which is not installed.\nyellowbrick 1.5 requires matplotlib!=3.0.0,>=2.0.2, which is not installed.\nyellowbrick 1.5 requires scikit-learn>=1.0.0, which is not installed.\nyellowbrick 1.5 requires scipy>=1.0.0, which is not installed.\nmlxtend 0.23.4 requires matplotlib>=3.0.0, which is not installed.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, which is not installed.\nmlxtend 0.23.4 requires scipy>=1.2.1, which is not installed.\nosqp 1.0.4 requires scipy>=0.13.2, which is not installed.\ngensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.3.2 which is incompatible.\nmkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.2 which is incompatible.\nmkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.2 which is incompatible.\nmkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.3.2 which is incompatible.\ncupy-cuda12x 13.4.1 requires numpy<2.3,>=1.22, but you have numpy 2.3.2 which is incompatible.\nnumba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.3.2 which is incompatible.\ngoogle-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 6.32.0 which is incompatible.\nydata-profiling 4.16.1 requires numpy<2.2,>=1.16.0, but you have numpy 2.3.2 which is incompatible.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 6.32.0 which is incompatible.\nkaggle-environments 1.17.6 requires transformers>=4.33.1, but you have transformers 4.25.1 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.1 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\npandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nsentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.25.1 which is incompatible.\ngoogle-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.32.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.6.1 which is incompatible.\nlangchain-core 0.3.66 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\nfastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.8.0 which is incompatible.\ngoogle-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\ndataproc-spark-connect 0.7.5 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\njupyter-kernel-gateway 2.5.2 requires jupyter-client<8.0,>=5.2.0, but you have jupyter-client 8.6.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed MarkupSafe-3.0.2 absl-py-2.3.1 cachetools-5.5.2 certifi-2025.8.3 charset_normalizer-3.4.3 google-auth-2.40.3 google-auth-oauthlib-1.0.0 grpcio-1.74.0 idna-3.10 markdown-3.8.2 numpy-2.3.2 oauthlib-3.3.1 protobuf-6.32.0 pyasn1-0.6.1 pyasn1-modules-0.4.2 requests-2.32.5 requests-oauthlib-2.0.0 rsa-4.9.1 setuptools-80.9.0 tensorboard-2.13.0 tensorboard-data-server-0.7.2 urllib3-2.5.0 werkzeug-3.1.3 wheel-0.45.1\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom torch.utils.tensorboard import SummaryWriter\n\nprint(f\"✅ NumPy: {np.__version__}\")\n\nprint(f\"✅ PyTorch: {torch.__version__}\")\nprint(\"✅ All imports successful!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T17:37:37.618463Z","iopub.execute_input":"2025-08-24T17:37:37.618777Z","iopub.status.idle":"2025-08-24T17:37:39.452752Z","shell.execute_reply.started":"2025-08-24T17:37:37.618747Z","shell.execute_reply":"2025-08-24T17:37:39.452190Z"}},"outputs":[{"name":"stdout","text":"✅ NumPy: 1.26.4\n✅ PyTorch: 2.8.0+cu128\n✅ All imports successful!\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"os.makedirs(\"/kaggle/working/roberta_custom\", exist_ok=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T17:40:13.628727Z","iopub.execute_input":"2025-08-24T17:40:13.629550Z","iopub.status.idle":"2025-08-24T17:40:13.633524Z","shell.execute_reply.started":"2025-08-24T17:40:13.629519Z","shell.execute_reply":"2025-08-24T17:40:13.632789Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"!python train_roberta.py \\\n    --data_path /kaggle/working/dataset/longbench_1_filtered.pt \\\n    --save_path /kaggle/working/roberta_custom \\\n    --num_epoch 3 \\\n    --lr 3e-5 \\\n    --quantization float16 \\\n    --batch_size 16\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-24T17:40:15.567582Z","iopub.execute_input":"2025-08-24T17:40:15.567841Z","iopub.status.idle":"2025-08-24T17:40:44.344353Z","shell.execute_reply.started":"2025-08-24T17:40:15.567822Z","shell.execute_reply":"2025-08-24T17:40:44.343418Z"}},"outputs":[{"name":"stdout","text":"CUDA test successful on cuda\n/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\nLoading model with float16 precision\nSome weights of the model checkpoint at FacebookAI/xlm-roberta-large were not used when initializing XLMRobertaForTokenClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias']\n- This IS expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-large and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nModel memory footprint: 1.12 GB\nTraining set: 3, Validation set: 1\nSample data: {'ids': tensor([     0,  46692,    152,  16173,    242,      7, 108787,     70,     21,\n         44413,    429,    289,    502,   7732,    329,     15,  39210,    538,\n         15005,     47,    237,  16173,    242,      7, 108787,   1388,     10,\n         60213,    111,     70,  14135,    108,   2594,    186,     70,      6,\n        122077,    707,    502,   9774,   6889,    450,    186,   3173,    390,\n            70,  55291,    111,     70,  96055,  63964,  89206,  23573,    613,\n         67688,     70,     21,  44413,    425,      6,      5,  45646,     70,\n         45646,    111,     70,     21,  44413,    429,    289,    502,   7732,\n           329,   3173,     10,    373,   2676,   1379,     70,  21722,      6,\n             5,    442,    186,  21334,     23,  25171,    332,     23, 136565,\n           442,    186,  56104, 123019,  75693,    136, 180629,   2886,      6,\n             5,     23,  46667,     70,    373,   2676,    186,   5045,  40715,\n         75693,    136,    186,   7941,    538,    117,    329,   5844,     98,\n            70,   1407,     56, 121303,    111,     70,  96055,  63964,  89206,\n         23573,      6,      5,     70,  41714,   6275,    111,     70,   6626,\n        126826,    111,     70,  89206,  23573, 137567,   3173,    142,     10,\n         85691,  55291,     15,    111,   1672,   2510,  16207,   1388,     23,\n           332,  12960,     23,  46667,    442,   3173,    142,   9803,  46552,\n            15,    111,   1672,   5390,  16207,   1388,      6,      5,   1100,\n         60212, 102971,  15044,   1100,    765,    442,     70,  16173,    242,\n             7, 108787,    186,  16916,     47,    186,     10,  62816,  48242,\n         60213,    111,  25171,    332,   6637,   6863,  13267,  17660,     47,\n         51312,  15286,  38526,  20271, 148199,    939,      6,      5,   6863,\n         34754,    186,  16916,     10,  37526,   1294,  17688,  62816,  48242,\n           111,  11280,    450, 108975,    237,     10,  16750,    111, 147198,\n        103488,      6,      5,   6863,  17366,    111,  34754,    285,     53,\n         54940,  11651,    136,     70,  38134,    592,    111,    450,  16128,\n            23,     70,     21,  44413,    425,    831,  74918,   4552, 186683,\n           136,  69405,      6,      5,     70,     21,  44413,    429,    289,\n           502,   7732,    329,    186,   1286, 197097,     23,  25171,  11280,\n          3501,     23, 117776,   6637,    111,     70,  60212,     23,     70,\n         13267,    111,     70,  55291,    152,   2510,  16207,     23,  11280,\n           136,   5390,  16207,     23, 117776,      6,      5,  28670,  10763,\n            70,  16173,    242,      7, 108787,     23,    158,  17043,  10763,\n           678,     70,  96055,  63964,  89206,  23573,   3129,   3173,    442,\n          4358,     47,  59959,     70,  58982,    136,     70, 116619,   2831,\n           111,     70,     21,  44413,    425,  26698,     70, 108171,      6,\n         32271,     15,   3129,    186,  64040,     67, 105237,  50155,    442,\n          1388,      6,      5,    442,    186,   7413,     23,  15044,  46667,\n           136,    332,      6,      5,  15700,  32354,    111,     70,     21,\n         44413,    429,    289,    502,   7732,    329,    186,  33444,     13,\n            47,     70,      8,  64000,    592,    111,     70,  54479,      6,\n             5,  20271, 131970,   3956,     70,  96055,  63964,  89206,  23573,\n         55993,  25842,    678,     70,     21,  44413,    425,      6,      5,\n        210435,    538,     70,     21,  44413,    429,    289,    502,   7732,\n           329,  55993,     23,  13267,   5201,    538,     23,    332,      6,\n             5,  25842,     10,  21334,  45730,  24351,    186,   3249,   1257,\n            23,      6,  75189,   2320,  20939,  19481,    136,    237,     10,\n         16750,     70,    332,   2046,     10,  53894,  54479,  20537,      6,\n             5,  67081,    136,  29394, 102942,  54053,     47,  34390,     70,\n         13267,    111,     21,  44413,    429,    289,    502,   7732,    329,\n           186,  11782,    681,  39670,    320,     53,  19120,  72325,     53,\n            15,  96055,  63964,    681,  39670,  72325,     53,   1388,      6,\n             5,     70,  54053,    186,  60266,   6044,    450,  51455,   1363,\n         17660,     47,    186,  10846,    136,   2174,  13379,   3900,  18750,\n             6,      5,      2,      1,      1,      1,      1,      1,      1,\n             1,      1,      1,      1,      1,      1,      1,      1]), 'mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0]), 'targets': tensor([0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n        0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1,\n        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n        0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n        0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0])}\n<s>         0\n▁passage    0\n▁:          0\n▁Adam       1\n▁'          1\ns           1\n▁apple      1\n▁the        0\n▁la         1\nryn         1\nge          1\nal          1\n▁pro        1\nminen       1\nce          1\n▁(          0\n▁common     0\nly          0\n▁refer      0\n▁to         0\n▁as         0\n▁Adam       0\n▁'          0\ns           0\n▁apple      0\n▁)          0\n▁a          0\n▁feature    0\n▁of         0\n▁the        0\nInitial loss: 0.583984375\nLogits shape: torch.Size([1, 512, 2])\n  0%|                                                     | 0/3 [00:00<?, ?it/s]Training epoch: 1\nTraining loss per 100 training steps: 0.7085\nTraining loss epoch: 0.7085\nTraining accuracy epoch: 0.5235\nValidation Loss: nan\nValidation Accuracy: 0.5603\nNew best accuracy: 0.5603 - Model saved!\n 33%|███████████████                              | 1/3 [00:04<00:09,  4.83s/it]Training epoch: 2\nTraining loss per 100 training steps: nan\nTraining loss epoch: nan\nTraining accuracy epoch: 0.5309\nValidation Loss: nan\nValidation Accuracy: 0.5603\n 67%|██████████████████████████████               | 2/3 [00:05<00:02,  2.40s/it]Training epoch: 3\nTraining loss per 100 training steps: nan\nTraining loss epoch: nan\nTraining accuracy epoch: 0.5309\nValidation Loss: nan\nValidation Accuracy: 0.5603\n100%|█████████████████████████████████████████████| 3/3 [00:06<00:00,  2.03s/it]\nTraining completed!\n","output_type":"stream"}],"execution_count":15}]}